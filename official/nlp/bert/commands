source /home/ylyao/mybash
export MODEL=finetuning/$TASK/head_8

python ../data/create_finetuning_data.py \
 --input_data_dir=${GLUE_DIR}/${TASK_NAME} \
 --vocab_file=${BERT_DIR}/vocab.txt \
 --train_data_output_path=${OUTPUT_DIR}/${TASK_NAME}_train.tf_record \
 --eval_data_output_path=${OUTPUT_DIR}/${TASK_NAME}_eval.tf_record \
 --test_data_output_path=${OUTPUT_DIR}/${TASK_NAME}_test.tf_record \
 --meta_data_file_path=${OUTPUT_DIR}/${TASK_NAME}_meta_data \
 --fine_tuning_task_type=classification --max_seq_length=128 \
 --classification_task_name=${TASK_NAME}
#  --tfds_params="dataset=glue/rte,text_key=sentence1,text_b_key=sentence2"

python run_classifier.py \
    --mode='train_and_eval' \
    --input_meta_data_path=${OUTPUT_DIR}/${TASK}_meta_data \
    --train_data_path=${OUTPUT_DIR}/${TASK}_train.tf_record \
    --eval_data_path=${OUTPUT_DIR}/${TASK}_eval.tf_record \
    --bert_config_file=${BERT_DIR}/bert_config.json \
    --init_checkpoint=input_pretrain/head_8/pretrained/bert_model_step_10000.ckpt-5 \
    --train_batch_size=4 --eval_batch_size=4 \
    --steps_per_loop=1 \
    --learning_rate=2e-5 \
    --num_train_epochs=2 \
    --model_dir=$MODEL \
    --distribution_strategy=one_device

# python run_classifier_backup.py  \
#     8 0 8 \
#     --mode='predict' \
#     --input_meta_data_path=${OUTPUT_DIR}/${TASK}_meta_data \
#     --eval_data_path=${OUTPUT_DIR}/${TASK}_eval.tf_record \
#     --bert_config_file=${BERT_DIR}/bert_config.json \
#     --eval_batch_size=1 \
#     --model_dir=$MODEL \
#     --distribution_strategy=one_device

python run_classifier_backup.py  \
    8 0 1 \
    --mode='predict' \
    --input_meta_data_path=${OUTPUT_DIR}/${TASK}_meta_data \
    --eval_data_path=${OUTPUT_DIR}/${TASK}_eval.tf_record \
    --bert_config_file=${BERT_DIR}/bert_config.json \
    --eval_batch_size=1 \
    --model_dir=/home/ylyao/models/official/nlp/bert/head_1/model_dir_1/model_dir_temp \
    --distribution_strategy=one_device
