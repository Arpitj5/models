source /home/ylyao/mybash

cd input_pretrain

# num_layer=0
num_head=1

INPUTS_S="tf_len_128_0.tfrecord tf_len_128_1.tfrecord tf_len_128_2.tfrecord tf_len_128_3.tfrecord tf_len_128_4.tfrecord tf_len_128_5.tfrecord tf_len_128_6.tfrecord tf_len_128_7.tfrecord tf_len_128_8.tfrecord tf_len_128_9.tfrecord"
INPUTS_L=$(ls tf_len_512*)


for num_layer in 3
do
  MODEL_DIR=double_layer_${num_layer}/head_${num_head}
  MODEL_DIR_MIDDLE=${MODEL_DIR}_middle
  ORIGIN_MIDDLE=layer_${num_layer}/head_${num_head}_middle
  mkdir -p ${MODEL_DIR_MIDDLE}
  mkdir -p ${MODEL_DIR}


  python ../run_pretraining.py \
    ${num_head} ${num_layer} \
    --input_files=$INPUTS_S  \
    --bert_config_file=$BERT_DIR/bert_config.json \
    --max_seq_length=128 \
    --max_predictions_per_seq=20 \
    --num_train_epochs=20 \
    --train_batch_size=256 \
    --num_steps_per_epoch=9000 \
    --warmup_steps=10000 \
    --learning_rate=5e-5 \
    --model_dir=${MODEL_DIR_MIDDLE} > ${MODEL_DIR_MIDDLE}/logs


  python ../run_pretraining.py \
    ${num_head} ${num_layer} \
    --input_files=$INPUTS_L  \
    --bert_config_file=$BERT_DIR/bert_config.json \
    --init_checkpoint=${MODEL_DIR_MIDDLE}/pretrained/bert_model_step_180000.ckpt-20 \
    --max_seq_length=512 \
    --max_predictions_per_seq=20 \
    --num_train_epochs=10 \
    --train_batch_size=64 \
    --num_steps_per_epoch=2000 \
    --warmup_steps=10000 \
    --learning_rate=5e-5 \
    --model_dir=${MODEL_DIR} > ${MODEL_DIR}/logs
done
